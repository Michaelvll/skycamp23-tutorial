{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/skypilot-org/skypilot/master/docs/source/images/skypilot-wide-light-1k.png\" width=500>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Spot Instaces with SkyPilot\n",
    "SkyPilot supports managed spot jobs that can automatically recover from preemptions. This feature saves significant cost (e.g., up to 70% for GPU VMs) by making preemptible spot instances practical for long-running jobs.\n",
    "\n",
    "To maximize availability, SkyPilot automatically finds available spot resources across regions and clouds. Here is an example of BERT training job failing over different regions across AWS and GCP.\n",
    "\n",
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"https://skypilot.readthedocs.io/en/latest/_images/spot-training.png\" width=500>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements for using managed spot jobs on SkyPilot\n",
    "\n",
    "1. **Mounting code and datasets:** Local file mounts/workdir are not supported. Cloud buckets should be used to hold code and datasets, which can be satisfied by using SkyPilot Storage.\n",
    "\n",
    "2. **Saving and loading checkpoints:** (For ML jobs) Application code should save checkpoints periodically to a SkyPilot Storage-mounted cloud bucket. For job recovery, the program should try to reload a latest checkpoint from that path when it starts.\n",
    "\n",
    "We explain them in detail below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Mounting code and datasets\n",
    "\n",
    "To launch a spot job, users should upload their codebase and data to cloud buckets through SkyPilot Storage. Note that the cloud buckets can be mounted to VMs in different regions/clouds and thus enable enables transparent job relaunching without userâ€™s intervention. The YAML below shows an example.\n",
    "\n",
    "```yaml\n",
    "file_mounts:\n",
    "  /code:\n",
    "    name: # NOTE: Fill in your bucket name\n",
    "    source: /path/to/your/codebase\n",
    "    persistent: true\n",
    "    mode: COPY\n",
    "\n",
    "  # If data is stored locally\n",
    "  /data:\n",
    "    name: # NOTE: Fill in your bucket name\n",
    "    source: /path/to/your/dataset\n",
    "    persistent: true\n",
    "    mode: COPY\n",
    "\n",
    "  # If data is already on S3\n",
    "  /data2: s3://your-s3-bucket-name\n",
    "```\n",
    "\n",
    "### 2. Saving and loading checkpoints\n",
    "To allow spot recovery, another cloud bucket is typically needed for storing states of the job (e.g., model checkpoints). Below is an example of mounting a bucket to `/checkpoint`.\n",
    "\n",
    "```yaml\n",
    "file_mounts:\n",
    "  /checkpoint:\n",
    "    name: # NOTE: Fill in your bucket name\n",
    "    mode: MOUNT\n",
    "```\n",
    "\n",
    "The `MOUNT` mode in SkyPilot Storage ensures the checkpoints outputted to `/checkpoint` are automatically synced to a persistent bucket. Note that the application code should save program checkpoints periodically and reload those states when the job is restarted. This is typically achieved by reloading the latest checkpoint at the beginning of your program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An end-to-end example\n",
    "Below we show an example for fine-tuning a bert model on a question answering task with HuggingFace.\n",
    "\n",
    "```yaml\n",
    "# bert_qa.yaml\n",
    "name: bert_qa\n",
    "\n",
    "resources:\n",
    "  accelerators: V100:1\n",
    "  # NOTE: `use_spot` and `spot_recovery` are optional when using `sky spot launch`.\n",
    "  use_spot: true\n",
    "  # When a spot cluster is preempted, this strategy recovers by first waiting for\n",
    "  # the resources in the current region for a while (default: 3 minutes), and\n",
    "  # then failing over to other regions and clouds, until the resources are launched.\n",
    "  spot_recovery: FAILOVER\n",
    "\n",
    "file_mounts:\n",
    "  /checkpoint:\n",
    "    name: # NOTE: Fill in your bucket name\n",
    "    mode: MOUNT\n",
    "  /code:\n",
    "    name: # NOTE: Fill in your bucket name\n",
    "    # Assume your working directory is under `~/transformers`.\n",
    "    # To make this example work, please run the following command:\n",
    "    # git clone https://github.com/huggingface/transformers.git ~/transformers\n",
    "    source: ~/transformers\n",
    "    persistent: false\n",
    "    mode: COPY\n",
    "\n",
    "setup: |\n",
    "  # Fill in your wandb key: copy from https://wandb.ai/authorize\n",
    "  # Alternatively, you can use `--env WANDB_API_KEY=$WANDB_API_KEY`\n",
    "  # to pass the key in the command line, during `sky spot launch`.\n",
    "  echo export WANDB_API_KEY=[YOUR-WANDB-API-KEY] >> ~/.bashrc\n",
    "\n",
    "  cd /code && git checkout v4.18.0\n",
    "  pip install -e .\n",
    "  cd examples/pytorch/question-answering/\n",
    "  pip install -r requirements.txt\n",
    "  pip install wandb\n",
    "\n",
    "run: |\n",
    "  cd /code/examples/pytorch/question-answering/\n",
    "  python run_qa.py \\\n",
    "  --model_name_or_path bert-base-uncased \\\n",
    "  --dataset_name squad \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 50 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir /checkpoint/bert_qa/ \\\n",
    "  --report_to wandb \\\n",
    "  --save_total_limit 10 \\\n",
    "  --save_steps 1000\n",
    "```\n",
    "\n",
    "As HuggingFace has built-in support for periodically checkpointing, we only need to pass the below arguments for setting up the output directory and frequency of checkpointing (see more on Huggingface API).\n",
    "\n",
    "```\n",
    "python run_qa.py ... --output_dir /checkpoint/bert_qa/ --save_total_limit 10 --save_steps 1000\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run your spot job!\n",
    "\n",
    "With the above changes, you are ready to launch a spot job with sky spot launch!\n",
    "\n",
    "------------------\n",
    "```console\n",
    "sky spot launch -n bert-qa bert_qa.yaml\n",
    "```\n",
    "------------------\n",
    "\n",
    "SkyPilot will launch and start monitoring the spot job. When a preemption happens, SkyPilot will automatically search for resources across regions and clouds to re-launch the job.\n",
    "\n",
    "Here are some commands for managed spot jobs. Check `sky spot --help` for more details.\n",
    "\n",
    "------------------\n",
    "```\n",
    "# Check the status of the spot jobs\n",
    "$ sky spot status\n",
    "Fetching managed spot job status...\n",
    "Managed spot jobs:\n",
    "ID NAME     RESOURCES     SUBMITTED   TOT. DURATION   JOB DURATION   #RECOVERIES  STATUS\n",
    "2  roberta  1x [A100:8]   2 hrs ago   2h 47m 18s      2h 36m 18s     0            RUNNING\n",
    "1  bert-qa  1x [V100:1]   4 hrs ago   4h 24m 26s      4h 17m 54s     0            RUNNING\n",
    "\n",
    "# Stream the logs of a running spot job\n",
    "$ sky spot logs -n bert-qa\n",
    "\n",
    "# Cancel a spot job by name\n",
    "$ sky spot cancel -n bert-qa\n",
    "```\n",
    "------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
