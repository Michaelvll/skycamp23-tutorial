{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/skypilot-org/skypilot/master/docs/source/images/skypilot-wide-light-1k.png\" width=500>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using accelerators with SkyPilot\n",
    "\n",
    "Tasks in SkyPilot can request special resources for their execution. For instance, an ML training task can request Nvidia GPUs or Google TPUs for accelerated training, or a larger disk size.\n",
    "\n",
    "Additionally, SkyPilot can also run distributed tasks across many VMs, enabling usecases such as large scale distributed training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning outcomes üéØ\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "\n",
    "1. List the GPUs and Accelerators supported by SkyPilot. \n",
    "2. Specify different resource types (GPUs, TPUs) for your tasks.\n",
    "3. Use multiple nodes to run distributed tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing supported accelerators with `sky show-gpus`\n",
    "\n",
    "To see the list of accelerators supported by SkyPilot , you can use the `sky show-gpus` command. You can run `sky show-gpus` by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sky show-gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "-------------------------\n",
    "```console\n",
    "$ sky show-gpus\n",
    "NVIDIA_GPU  AVAILABLE_QUANTITIES  \n",
    "V100        1, 2, 4, 8            \n",
    "V100-32GB   8                     \n",
    "A100        1, 2, 4, 8, 16        \n",
    "A100-80GB   1, 2, 4, 8            \n",
    "P100        1, 2, 4               \n",
    "K80         1, 2, 4, 8, 16        \n",
    "T4          1, 2, 4, 8            \n",
    "M60         1, 2, 4               \n",
    "\n",
    "GOOGLE_TPU   AVAILABLE_QUANTITIES  \n",
    "tpu-v2-8     1                     \n",
    "tpu-v2-32    1                     \n",
    "tpu-v2-128   1                     \n",
    "tpu-v2-256   1                     \n",
    "tpu-v2-512   1                     \n",
    "tpu-v3-8     1                     \n",
    "tpu-v3-32    1                     \n",
    "tpu-v3-64    1                     \n",
    "tpu-v3-128   1                     \n",
    "tpu-v3-256   1                     \n",
    "tpu-v3-512   1                     \n",
    "tpu-v3-1024  1                     \n",
    "tpu-v3-2048  1  \n",
    "```\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **üí° Hint -** For a more extensive list of the GPUs supported by each cloud and their pricing information, run `sky show-gpus -a` in an interactive terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying resource requirements of tasks\n",
    "\n",
    "Special resource requirements are specified through the `resources` field in the SkyPilot task YAML. For example, to request 1 K80 GPU, simply add it to the YAML like so:\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  accelerators: K80:1\n",
    "\n",
    "setup: ....\n",
    "\n",
    "run: .....\n",
    "```\n",
    "\n",
    "> **üí° Hint -** In addition to `accelerators`, you can specify many more requirements, such as `disk_size`, a specific `cloud`, `region` or `zone`, `instance_type` and more! You can find more details in the [YAML configuration docs](https://skypilot.readthedocs.io/en/latest/reference/yaml-spec.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Edit `gpu_task.yaml` to use a K80 GPU! \n",
    "\n",
    "We have provided an example YAML (`gpu_task.yaml`) which runs `nvidia-smi`. However, it does not specify any GPU resources, so `nvidia-smi` would fail. \n",
    "\n",
    "Edit `gpu_task.yaml` to add the resources field to it! \n",
    "\n",
    "Your final YAML should look like this:\n",
    "\n",
    "---------------------\n",
    "```yaml\n",
    "# gpu_task.yaml\n",
    "name: gputask\n",
    "\n",
    "resources:\n",
    "  accelerators: K80:1\n",
    "\n",
    "run: |\n",
    "  nvidia-smi\n",
    "```\n",
    "---------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Launch your GPU accelerated task!\n",
    "\n",
    "**After you have edited `gpu_task.yaml`**, open a terminal and use `sky launch` to create a GPU cluster (We give it the name `gpu_cluster` using the `-c` flag):\n",
    "\n",
    "-------------------------\n",
    "```console\n",
    "sky launch -c gpu_cluster gpu_task.yaml\n",
    "```\n",
    "-------------------------\n",
    "\n",
    "### Expected output\n",
    "\n",
    "After the usual SkyPilot output, you should your task run:\n",
    "\n",
    "-------------------------\n",
    "```console\n",
    "$ sky launch gpu_task.yaml \n",
    "Task from YAML spec: gpu_task.yaml\n",
    "...\n",
    "(gputask pid=7660) Fri Sep  9 16:27:15 2022       \n",
    "(gputask pid=7660) +-----------------------------------------------------------------------------+\n",
    "(gputask pid=7660) | NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 11.4     |\n",
    "(gputask pid=7660) |-------------------------------+----------------------+----------------------+\n",
    "(gputask pid=7660) | GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "(gputask pid=7660) | Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "(gputask pid=7660) |                               |                      |               MIG M. |\n",
    "(gputask pid=7660) |===============================+======================+======================|\n",
    "(gputask pid=7660) |   0  Tesla K80           On   | 00000001:00:00.0 Off |                    0 |\n",
    "(gputask pid=7660) | N/A   25C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
    "(gputask pid=7660) |                               |                      |                  N/A |\n",
    "(gputask pid=7660) +-------------------------------+----------------------+----------------------+\n",
    "(gputask pid=7660)                                                                                \n",
    "(gputask pid=7660) +-----------------------------------------------------------------------------+\n",
    "(gputask pid=7660) | Processes:                                                                  |\n",
    "(gputask pid=7660) |  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "(gputask pid=7660) |        ID   ID                                                   Usage      |\n",
    "(gputask pid=7660) |=============================================================================|\n",
    "(gputask pid=7660) |  No running processes found                                                 |\n",
    "(gputask pid=7660) +-----------------------------------------------------------------------------+\n",
    "```\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíª Remember to terminate your cluster once you're done!\n",
    "\n",
    "-------------------------\n",
    "```console\n",
    "sky down gpu_cluster\n",
    "```\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Jobs on Many VMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SkyPilot supports multi-node cluster provisioning and distributed execution on many VMs.\n",
    "\n",
    "To request multiple nodes, simply add the `num_nodes` field YAML.\n",
    "\n",
    "For example, here's an example YAML training a ResNet model using pytorch distributed data-parallel. We provision two nodes, each with one V100 GPU.\n",
    "\n",
    "```yaml\n",
    "# distributed_training.yaml\n",
    "name: resnet-distributed-app\n",
    "\n",
    "resources:\n",
    "  accelerators: V100:1\n",
    "\n",
    "num_nodes: 2\n",
    "\n",
    "setup: |\n",
    "  pip3 install --upgrade pip\n",
    "  git clone https://github.com/michaelzhiluo/pytorch-distributed-resnet\n",
    "  cd pytorch-distributed-resnet && pip3 install -r requirements.txt\n",
    "  mkdir -p data  && mkdir -p saved_models && cd data && \\\n",
    "    wget -c --quiet https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
    "  tar -xvzf cifar-10-python.tar.gz\n",
    "\n",
    "run: |\n",
    "  cd pytorch-distributed-resnet\n",
    "\n",
    "  num_nodes=`echo \"$SKY_NODE_IPS\" | wc -l`\n",
    "  master_addr=`echo \"$SKY_NODE_IPS\" | head -n1`\n",
    "  python3 -m torch.distributed.launch --nproc_per_node=1 \\\n",
    "    --nnodes=$num_nodes --node_rank=${SKY_NODE_RANK} --master_addr=$master_addr \\\n",
    "    --master_port=8008 resnet_ddp.py --num_epochs 20\n",
    "```\n",
    "\n",
    "In the above, `num_nodes: 2` specifies that this task is to be run on 2 nodes. The setup and run commands are executed on both nodes.\n",
    "\n",
    "SkyPilot exposes two environment variables to distinguish per-node commands:\n",
    "\n",
    "* **`SKY_NODE_RANK`**: rank (an integer ID from 0 to `num_nodes-1`) of the node executing the task\n",
    "\n",
    "* **`SKY_NODE_IPS`**: a string of IP addresses of the nodes reserved to execute the task, where each line contains one IP address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üéâ Congratulations! You have completed this notebook. Please proceed to the next notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}