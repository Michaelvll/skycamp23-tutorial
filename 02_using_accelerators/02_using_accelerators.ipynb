{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\">\n",
    "    <img src=\"https://raw.githubusercontent.com/skypilot-org/skypilot/master/docs/source/images/skypilot-wide-light-1k.png\" width=500>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using accelerators and object stores to train ML Models 💨\n",
    "\n",
    "Tasks in SkyPilot can request special resources for their execution. For instance, an ML training task can request Nvidia GPUs or Google TPUs for accelerated training, or a larger disk size. SkyPilot handles provisioning and allocation of these specialized resources to tasks.\n",
    "\n",
    "Additionally, SkyPilot also allows tasks to access cloud object stores. It provides an easy to use interface for object stores which mounts the contents as files at a local path. Your datasets and dependencies stored in object stores can be directly accessed by SkyPilot tasks as if they were local files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning outcomes 🎯\n",
    "\n",
    "After completing this notebook, you will be able to:\n",
    "\n",
    "1. List the GPUs and Accelerators supported by SkyPilot. \n",
    "2. Specify different resource types (GPUs, TPUs) for your tasks.\n",
    "3. Access data on object stores directly from your tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:green\">[DIY]</span> Listing supported accelerators with `sky show-gpus`\n",
    "\n",
    "To see the list of accelerators supported by SkyPilot , you can use the `sky show-gpus` command. \n",
    "\n",
    "**Run `sky show-gpus` by running the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! sky show-gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected output\n",
    "-------------------------\n",
    "```console\n",
    "$ sky show-gpus\n",
    "NVIDIA_GPU  AVAILABLE_QUANTITIES  \n",
    "V100        1, 2, 4, 8            \n",
    "V100-32GB   8                     \n",
    "A100        1, 2, 4, 8, 16        \n",
    "A100-80GB   1, 2, 4, 8            \n",
    "P100        1, 2, 4               \n",
    "K80         1, 2, 4, 8, 16        \n",
    "T4          1, 2, 4, 8            \n",
    "M60         1, 2, 4               \n",
    "\n",
    "GOOGLE_TPU   AVAILABLE_QUANTITIES  \n",
    "tpu-v2-8     1                     \n",
    "tpu-v2-32    1                     \n",
    "tpu-v2-128   1                     \n",
    "tpu-v2-256   1                     \n",
    "tpu-v2-512   1                     \n",
    "tpu-v3-8     1                     \n",
    "tpu-v3-32    1                     \n",
    "tpu-v3-64    1                     \n",
    "tpu-v3-128   1                     \n",
    "tpu-v3-256   1                     \n",
    "tpu-v3-512   1                     \n",
    "tpu-v3-1024  1                     \n",
    "tpu-v3-2048  1  \n",
    "```\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **💡 Hint -** For a more extensive list of the GPUs supported by each cloud and their pricing information, run `sky show-gpus -a` in an interactive terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying resource requirements of tasks\n",
    "\n",
    "Special resource requirements are specified through the `resources` field in the SkyPilot task YAML. For example, to request 1 K80 GPU for your task, simply add it to the YAML like so:\n",
    "\n",
    "```yaml\n",
    "resources:\n",
    "  accelerators: K80:1\n",
    "\n",
    "setup: ....\n",
    "\n",
    "run: .....\n",
    "```\n",
    "\n",
    "> **💡 Hint -** In addition to `accelerators`, you can specify many more requirements, such as `disk_size`, a specific `cloud`, `region` or `zone`, `instance_type` and more! You can find more details in the [YAML configuration docs](https://skypilot.readthedocs.io/en/latest/reference/yaml-spec.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">[DIY]</span> 📝 Edit `bert.yaml` to use a K80 GPU! \n",
    "\n",
    "We have provided an example YAML (`bert.yaml`) which fine-tunes a BERT model on the SQuAD dataset. However, it does not specify any GPU resources for training.\n",
    "\n",
    "**Edit `bert.yaml` to add the resources field to it!**\n",
    "\n",
    "Your final YAML should have a `resources` field like this:\n",
    "\n",
    "---------------------\n",
    "```yaml\n",
    "...\n",
    "resources:\n",
    "  accelerators: K80:1\n",
    "...\n",
    "```\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing data from object stores "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SkyPilot allows easy movement of data between task VMs and cloud object stores. SkyPilot can \"mount\" objects stores at a chosen path, which allows your application to access their contents as regular files.\n",
    "\n",
    "These mount paths can be specified using the `file_mounts` field. For example, you may have noticed this in `bert.yaml`:\n",
    "\n",
    "-------------------\n",
    "```yaml\n",
    "file_mounts:\n",
    "  /dataset/:\n",
    "    source: s3://sky-bert-dataset/\n",
    "```\n",
    "-------------------\n",
    "\n",
    "This statement directs SkyPilot to mount the contents of `s3://sky-bert-dataset/` at `/dataset/`. When the task accesses contents of `/dataset/`, they are streamed from the `sky-bert-dataset` s3 bucket. As a result, **the application is able to use files and datasets stored in cloud object stores without any changes to its code**, simply reading the dataset as if it were a local file at /dataset/.\n",
    "\n",
    "> **💡 Hint** - In addition to object stores, SkyPilot can also copy files from your local machine to the remote VM! Refer to [SkyPilot docs](https://skypilot.readthedocs.io/en/latest/examples/syncing-code-artifacts.html) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">[DIY]</span> 💻 Launch your BERT training task!\n",
    "\n",
    "**After you have edited `bert.yaml` to use K80 GPUs, open a terminal and use `sky launch` to create a GPU cluster:**\n",
    "\n",
    "-------------------------\n",
    "```console\n",
    "sky launch 02_using_accelerators/bert.yaml\n",
    "```\n",
    "-------------------------\n",
    "\n",
    "This will take about two minutes.\n",
    "\n",
    "### Expected output\n",
    "\n",
    "After the usual SkyPilot output, you should see your task run:\n",
    "\n",
    "-------------------------\n",
    "```console\n",
    "$ sky launch bert.yaml \n",
    "Task from YAML spec: bert.yaml\n",
    "...\n",
    "(bert_qa pid=81384) Running tokenizer on validation dataset:  91%|█████████ | 10/11 [00:05<00:00,  1.68ba/s]\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1290] 2022-10-16 17:48:10,010 >> ***** Running training *****\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1291] 2022-10-16 17:48:10,011 >>   Num examples = 88524\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1292] 2022-10-16 17:48:10,011 >>   Num Epochs = 50\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1293] 2022-10-16 17:48:10,011 >>   Instantaneous batch size per device = 12\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1294] 2022-10-16 17:48:10,011 >>   Total train batch size (w. parallel, distributed & accumulation) = 12\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1295] 2022-10-16 17:48:10,011 >>   Gradient Accumulation steps = 1\n",
    "(bert_qa pid=81384) [INFO|trainer.py:1296] 2022-10-16 17:48:10,011 >>   Total optimization steps = 368850\n",
    "```\n",
    "-------------------------\n",
    "\n",
    "**After you see the task training output, hit `ctrl+c` to exit.**\n",
    "\n",
    "> **💡 Hint** - For long running tasks, you can safely Ctrl+C to exit once the task has started. It will continue running in the background. For more on how to access logs after detaching, queue more tasks and cancel tasks, please refer to [SkyPilot docs](https://skypilot.readthedocs.io/en/latest/reference/job-queue.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:green\">[DIY]</span> 💻 Remember to terminate your cluster once you're done!\n",
    "\n",
    "**Run `sky status` to get the cluster name and then use `sky down` to terminate it.**\n",
    "\n",
    "-------------------------\n",
    "```console\n",
    "$ sky status\n",
    "...\n",
    "$ sky down <cluster-name>\n",
    "```\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transparently training BERT on a different cloud\n",
    "Moving this complex BERT training job to a different cloud is easy with SkyPilot. \n",
    "\n",
    "**Even though this task requires access to accelerators and object stores, SkyPilot can seamlessly run this job on a different cloud with just one line change - adding the `--cloud` flag to `sky launch`.**\n",
    "\n",
    "Just like in the previous notebook, you can simply use the same YAML:\n",
    "\n",
    "-----------------\n",
    "```\n",
    "sky launch 02_using_accelerators/bert.yaml --cloud gcp\n",
    "```\n",
    "-----------------\n",
    "\n",
    "(In the interest of time, we don't run this command in this notebook but feel free to try it later!)\n",
    "\n",
    "SkyPilot will find instance types on GCP that support the required GPU, and it will also mount the object store when the task runs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 🎉 Congratulations! You have learnt how to use accelerators and cloud object stores in SkyPilot! Please proceed to the next notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
